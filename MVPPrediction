#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
mvp_prediction.py

Predict NBA MVP winners (1980–2024) without PER, with expanded output:
  • Inputs: NBA_Dataset.csv, mvp_history.csv,
            historical_RAPTOR_by_player.csv,
            modern_RAPTOR_by_player.csv
  • Models: Logistic Regression, Random Forest, XGBoost
  • Extra output: per‐model predicted MVP list, true vs. pred table,
                  confusion matrix, SHAP interpretability
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import shap

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.metrics import (
    classification_report,
    roc_auc_score,
    confusion_matrix
)


def load_data():
    """ Load MVP labels, base stats, and RAPTOR data from your CSVs. """
    # — MVP labels —
    mvp = pd.read_csv(
        "data/mvp_history.csv",
        skiprows=1,
        usecols=["Season", "Player"]
    )
    # Convert “1980-81”→1981, “2023-24”→2024
    mvp["season"] = (
        mvp["Season"]
        .str.split("-", expand=True)[0]
        .astype(int) + 1
    )
    mvp = (
        mvp.rename(columns={"Player": "player"})
           .loc[:, ["season", "player"]]
           .assign(MVP=1)
    )

    # — Season‐level box & advanced stats —
    bb = pd.read_csv("data/NBA_Dataset.csv")

    # — RAPTOR data (historical + modern) —
    rap_h = pd.read_csv("data/historical_RAPTOR_by_player.csv")
    rap_m = pd.read_csv("data/modern_RAPTOR_by_player.csv")
    rap_cols = ["player_name", "season", "raptor_offense", "raptor_defense", "raptor_total"]
    rap = (
        pd.concat([rap_h[rap_cols], rap_m[rap_cols]], ignore_index=True)
           .drop_duplicates(subset=["player_name", "season"])
           .rename(columns={"player_name": "player"})
    )

    return mvp, bb, rap


def preprocess_and_merge(mvp, bb, rap):
    """ Merge stats + RAPTOR + MVP labels, fill numeric gaps with medians. """
    df = (
        bb
        .merge(rap, on=["season", "player"], how="left")
        .merge(mvp, on=["season", "player"], how="left")
    )
    df["MVP"] = df["MVP"].fillna(0).astype(int)

    num_cols = df.select_dtypes(include=[np.number]).columns
    df[num_cols] = df[num_cols].fillna(df[num_cols].median())
    return df


def feature_engineering(df):
    """ Define feature columns and separate X, y. """
    feats = [
        'ws', 'bpm', 'vorp', 'win_loss_pct',
        'pts_per_g', 'trb_per_g', 'ast_per_g',
        'raptor_offense', 'raptor_defense', 'raptor_total'
    ]
    return df[feats], df["MVP"]


def train_models(X_train, y_train):
    """ Train LogisticRegression, RandomForest, and XGBoost. """
    models = {}

    # 1) Logistic Regression (with scaling)
    pipe = Pipeline([
        ("scaler", StandardScaler()),
        ("lr", LogisticRegression(max_iter=2000, random_state=42))
    ])
    pipe.fit(X_train, y_train)
    models["LogisticRegression"] = pipe

    # 2) Random Forest
    rf = RandomForestClassifier(
        n_estimators=300,
        max_depth=8,
        random_state=42,
        n_jobs=-1
    )
    rf.fit(X_train, y_train)
    models["RandomForest"] = rf

    # 3) XGBoost
    xg = xgb.XGBClassifier(
        n_estimators=300,
        learning_rate=0.05,
        use_label_encoder=False,
        eval_metric="logloss",
        random_state=42,
        n_jobs=-1
    )
    xg.fit(X_train, y_train)
    models["XGBoost"] = xg

    return models


def evaluate_and_report(models, df_test, X_test, y_test):
    """
    For each model:
      • Print classification report & ROC AUC & confusion matrix
      • List (season, player) predicted as MVP with probabilities
    Also show a side‑by‑side true vs. predicted table.
    """
    for name, model in models.items():
        y_pred = model.predict(X_test)
        y_prob = model.predict_proba(X_test)[:, 1]
        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

        print(f"\n=== {name} ===")
        print(classification_report(y_test, y_pred, digits=3))
        print(f"ROC AUC: {roc_auc_score(y_test, y_prob):.3f}")
        print(f"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}")

        # attach predictions back to df_test
        df_test[f"{name}_pred"] = y_pred
        df_test[f"{name}_prob"] = y_prob

        preds = df_test[df_test[f"{name}_pred"] == 1][["season", "player", f"{name}_prob"]]
        print(f"\n{name} predicted MVPs ({len(preds)}):")
        print(preds.to_string(index=False))

    # Show combined true vs. pred
    print("\n--- True vs. Predicted (first 10 rows) ---")
    cols = ["season", "player", "MVP"]
    for name in models:
        cols += [f"{name}_pred", f"{name}_prob"]
    print(df_test[cols].head(10).to_string(index=False))


def shap_summary(model_pipeline, X_ref, out="shap_summary.png"):
    """
    Extract the scaler and estimator from the LogisticRegression pipeline,
    then run Tree‐ or Kernel‐based SHAP on the scaled data.
    (Here we use shap.Explainer + Independent masker.)
    """
    # 1) get steps
    scaler = model_pipeline.named_steps["scaler"]
    estimator = model_pipeline.named_steps["lr"]

    # 2) scale your reference dataset
    X_scaled = scaler.transform(X_ref)

    # 3) build a SHAP Explainer on the bare estimator
    explainer = shap.Explainer(
        estimator.predict, 
        masker=shap.maskers.Independent(X_scaled)
    )
    shap_vals = explainer(X_scaled)

    # 4) summary plot
    shap.summary_plot(
        shap_vals, X_scaled,
        feature_names=X_ref.columns,
        show=False
    )
    plt.tight_layout()
    plt.savefig(out)
    print(f"SHAP summary plot saved to {out}")


def main():
    # 1) Load & merge
    mvp, bb, rap = load_data()
    df = preprocess_and_merge(mvp, bb, rap)

    # 2) Feature/target split
    X, y = feature_engineering(df)

    # 3) Train/test split (preserve indices for reporting)
    idx = df.index.to_numpy()
    X_tr, X_te, y_tr, y_te, idx_tr, idx_te = train_test_split(
        X, y, idx,
        test_size=0.20,
        stratify=y,
        random_state=42
    )

    # Build a test‐set DataFrame for human‐readable output
    df_test = df.loc[idx_te, ["season", "player", "MVP"]].reset_index(drop=True)

    # 4) Train models
    models = train_models(X_tr, y_tr)

    # 5) Evaluate & detailed report
    evaluate_and_report(models, df_test, X_te, y_te)

    # 6) SHAP interpretation on LogisticRegression
    shap_summary(models["LogisticRegression"], X_tr)


if __name__ == "__main__":
    main()
