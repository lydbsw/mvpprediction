{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375e3978",
   "metadata": {},
   "source": [
    "# NBA MVP Prediction Using Machine Learning\n",
    "This notebook follows the same structure as `mvp_prediction.py`, loading data, preprocessing, training three models (Logistic Regression, Random Forest, XGBoost), evaluating them, plotting ROC curves, and running SHAP interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6560847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve, \n",
    "    make_scorer, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# Load data\n",
    "mvp = pd.read_csv(\"data/mvp_history.csv\", skiprows=1, usecols=[\"Season\", \"Player\"])\n",
    "mvp[\"season\"] = mvp[\"Season\"].str.split(\"-\", expand=True)[0].astype(int) + 1\n",
    "mvp = mvp.rename(columns={\"Player\": \"player\"})[[\"season\", \"player\"]].assign(MVP=1)\n",
    "\n",
    "bb = pd.read_csv(\"data/NBA_Dataset.csv\")\n",
    "rap_h = pd.read_csv(\"data/historical_RAPTOR_by_player.csv\")\n",
    "rap_m = pd.read_csv(\"data/modern_RAPTOR_by_player.csv\")\n",
    "rap_cols = [\"player_name\", \"season\", \"raptor_offense\", \"raptor_defense\", \"raptor_total\"]\n",
    "rap = pd.concat([rap_h[rap_cols], rap_m[rap_cols]], ignore_index=True)\n",
    "rap = rap.drop_duplicates(subset=[\"player_name\", \"season\"]).rename(columns={\"player_name\": \"player\"})\n",
    "\n",
    "df = bb.merge(rap, on=[\"season\", \"player\"], how=\"left\").merge(mvp, on=[\"season\", \"player\"], how=\"left\")\n",
    "df[\"MVP\"] = df[\"MVP\"].fillna(0).astype(int)\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f32da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "features = [\n",
    "    'ws', 'bpm', 'vorp', 'win_loss_pct',\n",
    "    'pts_per_g', 'trb_per_g', 'ast_per_g',\n",
    "    'raptor_offense', 'raptor_defense', 'raptor_total'\n",
    "]\n",
    "X = df[features]\n",
    "y = df[\"MVP\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Train models\n",
    "models = {\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "    ]).fit(X_tr, y_tr),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=8, random_state=42, n_jobs=1\n",
    "    ).fit(X_tr, y_tr),\n",
    "    \"XGBoost\": xgb.XGBClassifier(\n",
    "        n_estimators=300, learning_rate=0.05,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42, n_jobs=1\n",
    "    ).fit(X_tr, y_tr)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation & Reporting\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_prob = model.predict_proba(X_te)[:, 1]\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(classification_report(y_te, y_pred, digits=3))\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_te, y_prob):.3f}\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "    print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "plt.figure()\n",
    "for name, model in models.items():\n",
    "    probas = model.predict_proba(X_te)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_te, probas)\n",
    "    auc = roc_auc_score(y_te, probas)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves for MVP Prediction Models\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb6056",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    if name == \"XGBoost\":\n",
    "        booster = model.get_booster()\n",
    "        score = booster.get_score(importance_type=\"gain\")\n",
    "        importances = pd.Series(score).reindex(features).fillna(0)\n",
    "    elif hasattr(model, \"feature_importances_\"):\n",
    "        importances = pd.Series(model.feature_importances_, index=features)\n",
    "    else:\n",
    "        print(f\"Skipping {name} (no native feature importance)\")\n",
    "        continue\n",
    "\n",
    "    importances = importances.sort_values(ascending=False)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    importances.plot(kind=\"barh\")\n",
    "    plt.title(f\"{name} Feature Importance\")\n",
    "    plt.xlabel(\"Importance Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP interpretability for Logistic Regression\n",
    "scaler = models[\"LogisticRegression\"].named_steps[\"scaler\"]\n",
    "estimator = models[\"LogisticRegression\"].named_steps[\"lr\"]\n",
    "X_scaled = scaler.transform(X_tr)\n",
    "\n",
    "explainer = shap.Explainer(estimator.predict, masker=shap.maskers.Independent(X_scaled))\n",
    "shap_vals = explainer(X_scaled)\n",
    "shap.summary_plot(\n",
    "    shap_vals, \n",
    "    X_scaled, \n",
    "    feature_names=features, \n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary — Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe65c52",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The shape of the shap_values matrix does not match the shape of the provided data matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m shap_vals_rf_all \u001b[38;5;241m=\u001b[39m explainer_rf\u001b[38;5;241m.\u001b[39mshap_values(X_scaled)\n\u001b[1;32m      5\u001b[0m shap_vals_rf     \u001b[38;5;241m=\u001b[39m shap_vals_rf_all[\u001b[38;5;241m1\u001b[39m]   \u001b[38;5;66;03m# choose the positive‐class (1) array\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshap_vals_rf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHAP Summary — Random Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/shap/plots/_beeswarm.py:667\u001b[0m, in \u001b[0;36msummary_legacy\u001b[0;34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale, rng)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    663\u001b[0m             shape_msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Perhaps the extra column in the shap_values matrix is the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant offset? Of so just pass shap_values[:,:-1].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m         )\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m num_features \u001b[38;5;241m==\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], shape_msg\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFEATURE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features)])\n",
      "\u001b[0;31mAssertionError\u001b[0m: The shape of the shap_values matrix does not match the shape of the provided data matrix."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Random Forest SHAP ---\n",
    "explainer_rf      = shap.TreeExplainer(models[\"RandomForest\"])\n",
    "shap_vals_rf_all  = explainer_rf.shap_values(X_scaled)  \n",
    "\n",
    "# pick out the “positive” class (class index 1) across the third axis\n",
    "shap_vals_rf = shap_vals_rf_all[:, :, 1]  \n",
    "\n",
    "# now shap_vals_rf has shape (n_samples, n_features), so it will line up\n",
    "shap.summary_plot(\n",
    "    shap_vals_rf,\n",
    "    X_scaled,\n",
    "    feature_names=features,\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary — Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca64c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XGBoost SHAP ---\n",
    "explainer_xgb = shap.TreeExplainer(models[\"XGBoost\"])\n",
    "shap_vals_xgb = explainer_xgb(X_scaled)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_vals_xgb,\n",
    "    X_scaled,\n",
    "    feature_names=features,\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary — XGBoost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa48bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"=== Cross-Validation Results ===\")\n",
    "for name, model in models.items():\n",
    "    if name == \"LogisticRegression\":\n",
    "        X_input = X_tr\n",
    "        model_cv = model\n",
    "    else:\n",
    "        X_input = X_tr\n",
    "        model_cv = model\n",
    "\n",
    "    scores = cross_val_score(model_cv, X_input, y_tr, cv=cv, scoring=\"roc_auc\")\n",
    "    print(f\"{name}: Mean ROC AUC = {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid_log = {\n",
    "    \"logreg__penalty\": [\"l2\", \"l1\"],\n",
    "    \"logreg__C\": [0.01, 0.1, 1, 10],\n",
    "}\n",
    "logreg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=9000, solver=\"saga\"))\n",
    "])\n",
    "grid_log = GridSearchCV(logreg_pipeline, param_grid_log, cv=3, scoring=\"f1_macro\", n_jobs=-1)\n",
    "grid_log.fit(X_tr, y_tr)\n",
    "\n",
    "best_logreg = grid_log.best_estimator_\n",
    "print(\"Best Logistic Regression Params:\", grid_log.best_params_)\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 100],\n",
    "    \"max_depth\": [5, 10, None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"class_weight\": [\"balanced\"]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, scoring=\"f1_macro\", n_jobs=-1)\n",
    "grid_rf.fit(X_tr, y_tr)\n",
    "\n",
    "best_rf = grid_rf.best_estimator_\n",
    "print(\"Best Random Forest Params:\", grid_rf.best_params_)\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [50, 100],\n",
    "    \"max_depth\": [3, 6],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(XGBClassifier(eval_metric=\"mlogloss\"), param_grid_xgb, cv=3, scoring=\"f1_macro\", n_jobs=-1)\n",
    "grid_xgb.fit(X_tr, y_tr)\n",
    "\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "print(\"Best XGBoost Params:\", grid_xgb.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
